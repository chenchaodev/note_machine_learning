{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Linear Models\n",
    "\n",
    "$$\\hat{y}(\\omega, x) = \\omega_0 + \\omega_1 x_1 + ... + \\omega_p x_p$$\n",
    "\n",
    "def $$\\vec{\\omega} = (\\omega_1, ..., \\omega_p)$$ as `coef_` and $$\\omega_0$$ as `intercept_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares\n",
    "$ \\min\\limits_\\omega || X_\\omega - y ||_2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit([[0, 0], [1,1], [2,2]], [1, 2, 3])\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "[Linear Regression Example](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#example-linear-model-plot-ols-py)\n",
    "[google]\n",
    "[google]: http://www.google.com/        \"Google test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares Complexity\n",
    "if X is a matrix of size(n, p), has a cost of $O(np^2)$ , assuming that $ n \\geq p $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\min\\limits_\\omega || X_\\omega - y|| _2 ^2 + \\alpha ||\\omega||_2^2 $$\n",
    "\n",
    "in which, $$ \\alpha \\geq 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Ridge(alpha=.5)\n",
    "clf.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.34545455,  0.34545455]), 0.13636363636363641)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "- [Plot Ridge coefficients as a function of the regularization]\n",
    "- [Classification of text documents using sparse features]\n",
    "[Plot Ridge coefficients as a function of the regularization]: http://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html#example-linear-model-plot-ridge-path-py       \"Plot Ridge coefficients as a function of the regularization\"\n",
    "\n",
    "[Classification of text documents using sparse features]: http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py \"Classification of text documents using sparse features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Complexity\n",
    "same order of complexity than ordinary least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the regularization parameters: generalized Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=[0.1, 1, 10], cv=None, fit_intercept=True, gcv_mode=None,\n",
       "    normalize=False, scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.RidgeCV(alphas = [.1, 1, 10])\n",
    "clf.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\min \\limits_\\omega \\frac{1}{2n_{samples}} || X_\\omega - y|| _2^2 + \\alpha||\\omega||_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit([[0,0], [1, 1]], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example\n",
    "- [Lasso and Elastic Net for Sparse Signals]\n",
    "- [Compressive sensing: tomography reconstruction with L1 prior (Lasso)]\n",
    "\n",
    "[Lasso and Elastic Net for Sparse Signals]: http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_and_elasticnet.html#example-linear-model-plot-lasso-and-elasticnet-py \"Lasso and Elastic Net for Sparse Signals\"\n",
    "\n",
    "[Compressive sensing: tomography reconstruction with L1 prior (Lasso)]: http://scikit-learn.org/stable/auto_examples/applications/plot_tomography_l1_reconstruction.html#example-applications-plot-tomography-l1-reconstruction-py \"Compressive sensing: tomography reconstruction with L1 prior (Lasso)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future selection with Lasso\n",
    "- [L1-based feature selection]\n",
    "\n",
    "[L1-based feature selection]: http://scikit-learn.org/stable/modules/feature_selection.html#l1-feature-selection \"L1-based feature selection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized sparsity\n",
    "- [Randomized sparse models]\n",
    "\n",
    "[Randomized sparse models]: http://scikit-learn.org/stable/modules/feature_selection.html#randomized-l1 \"Randomized sparse models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting regularization parameter\n",
    "- $\\alpha$ controls the degree of sparsity of the coefficients estimated\n",
    "\n",
    "##### Using cross-validation\n",
    "- LassoCV, often used\n",
    "- LassoLarsCV, based on the Least Angle Regression, exploring more relevant values, Often fast\n",
    "\n",
    "##### information-criteria based model selection\n",
    "- [Lasso model selection: Cross-Validation / AIC / BIC]\n",
    "\n",
    "[Lasso model selection: Cross-Validation / AIC / BIC]: http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html#example-linear-model-plot-lasso-model-selection-py \"Lasso model selection: Cross-Validation / AIC / BIC\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "### Multi-task Lasso\n",
    "### Least Angle Regression\n",
    "### LARS Lasso\n",
    "### Orthogonal Matching Pursuit (OMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- logistic function\n",
    "    $$ f(x) = \\frac{L}{1+ e^{-k(x-x_0)}}$$\n",
    "- use class LogisticRegression \n",
    "    can fit a multiclass(one-vs-rest) LR with optional L2 or L1 regularization\n",
    "- L2 penalized\n",
    "    $$ \\min\\limits_{\\omega,c}\\frac{1}{2}\\omega^T\\omega + C\\sum_{i=1}^n\\log(\\exp(-y_i(X^T\\omega +c))+1) $$\n",
    "- L1 penalized\n",
    "    $$ \\min\\limits_{\\omega, c} ||\\omega||_1 + C\\sum_{i=1}^n\\log(\\exp(-y_i(X^T\\omega+c))+1) $$\n",
    "- choosing sover\n",
    "    - Small dataset or L1 penaalty: `liblinear`\n",
    "    - Multinomial loss: `lbfgs` or `newton-cg`\n",
    "    - Large dataset: `sag`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "- [L1 Penalty and Sparsity in Logistic Regression]\n",
    "- [Path with L1- Logistic Regression]\n",
    "\n",
    "[L1 Penalty and Sparsity in Logistic Regression]: http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html#example-linear-model-plot-logistic-l1-l2-sparsity-py \"L1 Penalty and Sparsity in Logistic Regression\"\n",
    "\n",
    "[Path with L1- Logistic Regression]: http://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_path.html#example-linear-model-plot-logistic-path-py \"Path with L1- Logistic Regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differences from liblinear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featur selection with sparse logistic regression\n",
    "- [L1-based feature selection]\n",
    "- `LogisticRegressionCV`\n",
    "[L1-based feature selection]: http://scikit-learn.org/stable/modules/feature_selection.html#l1-feature-selection \"L1-based feature selection\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
